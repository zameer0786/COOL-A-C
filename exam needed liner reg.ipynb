{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the necessary EDA\n",
    "# Data shoukd be contionous numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw OLS for entire datasset\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_constant = sm.add_constant(X)  # To learn b0 . linear regressin model will learn bo by defalut but we have to pass as parameter in ols\n",
    "model = sm.OLS(y,X_constant).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for predicted and residual values\n",
    "predictedvalues = model.predict()\n",
    "resids = model.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumptions for entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumption 1- No autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from ols summary\n",
    "# Durbin-Watson test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumption 2- Normality of Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The second assumption is the Normality of Residuals. \n",
    "For this we prefer the Jarque Bera test. For a good model, the residuals should be normally distributed.\n",
    "The higher the value of Jarque Bera test , the lesser the residuals are normally distributed.\n",
    "We generally prefer a lower value of jarque bera test.\n",
    "\n",
    "The Jarque–Bera test is a goodness-of-fit test of whether sample data \n",
    "have the skewness and kurtosis matching a normal distribution.\n",
    "And jarque-bera test (test for normality) : 783.126\n",
    "    \n",
    "The jarque bera test tests whether the sample data has the skewness and kurtosis matching a normal distribution.\n",
    "Note that this test generally works good for large enough number of data samples(>2000) as the test statistics asymptotically has a chi squared distribution with degrees 2 of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print(stats.jarque_bera(model.resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical chi square value at the 5% level of significance is 5.99. If the computed value exceeds this value the null hypothesis is rejected.\n",
    "\n",
    "In this case the computed value of the JB statistic 783.13 is greater than 5.99. Thus we reject the null hypothesis that the error terms are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Asssumption 3 - Linearity of residuals\n",
    "Here we have 2 options. Either we can plot the observed values Vs predicted values and plot the Residual Vs predicted values and see the linearity of residuals.\n",
    "OR\n",
    "We can go for rainbow test. Let's look both of them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rainbow test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "sm.stats.diagnostic.linear_rainbow(res=model, frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resid.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for homoscadisticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot a scatter plot of pred vs residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumption 5- NO  MULTI COLLINEARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The interpretation of VIF is as follows: the square root of a given variable’s VIF shows how much larger the standard error is,\n",
    "compared with what it would be if that predictor were uncorrelated with the other features in the model.\n",
    "If no features are correlated, then all values for VIF will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\n",
    "pd.DataFrame({'vif': vif[1:]}, index=X.columns).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Assumptions, #### Step 2 : Construct residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['predictions'] = model.predict(X_constant)\n",
    "residuals = model.resid\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.residplot(df1.predictions, residuals, lowess = True, color = 'g')\n",
    "ax.set(xlabel = 'Fitted value', ylabel = 'Residuals', title = 'Residual vs Fitted Plot \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do linear regression model for training and testing data and find r2 and adj r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "print(f'Coefficients: {lin_reg.coef_}')\n",
    "print(f'Intercept: {lin_reg.intercept_}')\n",
    "print(f'R^2 score: {lin_reg.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE = SSE /(no of obs-no of parameters) for the predicted values\n",
    "#RMSE = sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_test, y_test)\n",
    "\n",
    "print(f'Coefficients: {lin_reg.coef_}')\n",
    "print(f'Intercept: {lin_reg.intercept_}')\n",
    "print(f'R^2 score: {lin_reg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values for testing data\n",
    "Y_predicted=lin_reg.predict(X_test)\n",
    "plt.plot(X_test,Y_predicted,marker='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do necessary Transformations for the columns  without dummies if assumptions donot meet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,13)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization - Lasso , Ridge , Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher the alpha value, more restriction on the coefficients; \n",
    "# low alpha > more generalization, coefficients are barely\n",
    "rr = Ridge(alpha=0.01) \n",
    "# restricted and in this case linear and ridge regression resembles\n",
    "rr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr100 = Ridge(alpha=100) #  comparison with alpha value\n",
    "rr100.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=lr.score(X_train, y_train)\n",
    "test_score=lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_train_score = rr.score(X_train,y_train)\n",
    "Ridge_test_score = rr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_train_score100 = rr100.score(X_train,y_train)\n",
    "Ridge_test_score100 = rr100.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"linear regression train score:\", train_score)\n",
    "print(\"linear regression test score:\", test_score)\n",
    "print(\"ridge regression train score low alpha:\", Ridge_train_score)\n",
    "print(\"ridge regression test score low alpha:\", Ridge_test_score)\n",
    "print(\"ridge regression train score high alpha:\", Ridge_train_score100)\n",
    "print(\"ridge regression test score high alpha:\", Ridge_test_score100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try for various aplha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rr.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\\alpha = 0.01$',zorder=7) # zorder for ordering the markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's perform a cross-validation to find the best combination of alpha and l1_ratio\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "cv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, .995, 1], eps=0.001, n_alphas=100, fit_intercept=True, \n",
    "                        normalize=True, precompute='auto', max_iter=2000, tol=0.0001, cv=5, \n",
    "                        copy_X=True, verbose=0, n_jobs=-1, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-52858476d1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "cv_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal alpha: %.8f'%cv_model.alpha_)\n",
    "print('Optimal l1_ratio: %.3f'%cv_model.l1_ratio_)\n",
    "print('Number of iterations %d'%cv_model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with best parameters from CV\n",
    "model = ElasticNet(l1_ratio=cv_model.l1_ratio_, alpha = cv_model.alpha_, max_iter=cv_model.n_iter_, fit_intercept=True, normalize = True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_train, model.predict(X_train))) # training data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test, model.predict(X_test))) # test data performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
